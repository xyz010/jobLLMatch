{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_jd = \"/Users/andreasloutzidis/Downloads/jobLLMatch/Datasets/job_descriptions\"\n",
    "data_res = \"/Users/andreasloutzidis/Downloads/jobLLMatch/Datasets/resume\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# UpdatedResumeDataSet.csv [Resumes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/andreasloutzidis/Downloads/jobLLMatch/Datasets/resume/UpdatedResumeDataSet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_updatedResumeDataset \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUpdatedResumeDataSet.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_updatedResumeDataset\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_updatedResumeDataset\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/andreasloutzidis/Downloads/jobLLMatch/Datasets/resume/UpdatedResumeDataSet.csv'"
     ]
    }
   ],
   "source": [
    "df_updatedResumeDataset = pd.read_csv(os.path.join(data_res, \"UpdatedResumeDataSet.csv\"))\n",
    "print(f\"Shape: {df_updatedResumeDataset.shape}\")\n",
    "df_updatedResumeDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample Skills * Programming Languages: Python (pandas, numpy, scipy, scikit-learn, matplotlib), Sql, Java, JavaScript/JQuery. * Machine learning: Regression, SVM, NaÃ¯ve Bayes, KNN, Random Forest, Decision Trees, Boosting techniques, Cluster Analysis, Word Embedding, Sentiment Analysis, Natural Language processing, Dimensionality reduction, Topic Modelling (LDA, NMF), PCA & Neural Nets. * Database Visualizations: Mysql, SqlServer, Cassandra, Hbase, ElasticSearch D3.js, DC.js, Plotly, kibana, matplotlib, ggplot, Tableau. * Others: Regular Expression, HTML, CSS, Angular 6, Logstash, Kafka, Python Flask, Git, Docker, computer vision - Open CV and understanding of Deep learning.Education Details \n",
      "\n",
      "Data Science Assurance Associate \n",
      "\n",
      "Data Science Assurance Associate - Ernst & Young LLP\n",
      "Skill Details \n",
      "JAVASCRIPT- Exprience - 24 months\n",
      "jQuery- Exprience - 24 months\n",
      "Python- Exprience - 24 monthsCompany Details \n",
      "company - Ernst & Young LLP\n",
      "description - Fraud Investigations and Dispute Services   Assurance\n",
      "TECHNOLOGY ASSISTED REVIEW\n",
      "TAR (Technology Assisted Review) assists in accelerating the review process and run analytics and generate reports.\n",
      "* Core member of a team helped in developing automated review platform tool from scratch for assisting E discovery domain, this tool implements predictive coding and topic modelling by automating reviews, resulting in reduced labor costs and time spent during the lawyers review.\n",
      "* Understand the end to end flow of the solution, doing research and development for classification models, predictive analysis and mining of the information present in text data. Worked on analyzing the outputs and precision monitoring for the entire tool.\n",
      "* TAR assists in predictive coding, topic modelling from the evidence by following EY standards. Developed the classifier models in order to identify \"red flags\" and fraud-related issues.\n",
      "\n",
      "Tools & Technologies: Python, scikit-learn, tfidf, word2vec, doc2vec, cosine similarity, NaÃ¯ve Bayes, LDA, NMF for topic modelling, Vader and text blob for sentiment analysis. Matplot lib, Tableau dashboard for reporting.\n",
      "\n",
      "MULTIPLE DATA SCIENCE AND ANALYTIC PROJECTS (USA CLIENTS)\n",
      "TEXT ANALYTICS - MOTOR VEHICLE CUSTOMER REVIEW DATA * Received customer feedback survey data for past one year. Performed sentiment (Positive, Negative & Neutral) and time series analysis on customer comments across all 4 categories.\n",
      "* Created heat map of terms by survey category based on frequency of words * Extracted Positive and Negative words across all the Survey categories and plotted Word cloud.\n",
      "* Created customized tableau dashboards for effective reporting and visualizations.\n",
      "CHATBOT * Developed a user friendly chatbot for one of our Products which handle simple questions about hours of operation, reservation options and so on.\n",
      "* This chat bot serves entire product related questions. Giving overview of tool via QA platform and also give recommendation responses so that user question to build chain of relevant answer.\n",
      "* This too has intelligence to build the pipeline of questions as per user requirement and asks the relevant /recommended questions.\n",
      "\n",
      "Tools & Technologies: Python, Natural language processing, NLTK, spacy, topic modelling, Sentiment analysis, Word Embedding, scikit-learn, JavaScript/JQuery, SqlServer\n",
      "\n",
      "INFORMATION GOVERNANCE\n",
      "Organizations to make informed decisions about all of the information they store. The integrated Information Governance portfolio synthesizes intelligence across unstructured data sources and facilitates action to ensure organizations are best positioned to counter information risk.\n",
      "* Scan data from multiple sources of formats and parse different file formats, extract Meta data information, push results for indexing elastic search and created customized, interactive dashboards using kibana.\n",
      "* Preforming ROT Analysis on the data which give information of data which helps identify content that is either Redundant, Outdated, or Trivial.\n",
      "* Preforming full-text search analysis on elastic search with predefined methods which can tag as (PII) personally identifiable information (social security numbers, addresses, names, etc.) which frequently targeted during cyber-attacks.\n",
      "Tools & Technologies: Python, Flask, Elastic Search, Kibana\n",
      "\n",
      "FRAUD ANALYTIC PLATFORM\n",
      "Fraud Analytics and investigative platform to review all red flag cases.\n",
      "â¢ FAP is a Fraud Analytics and investigative platform with inbuilt case manager and suite of Analytics for various ERP systems.\n",
      "* It can be used by clients to interrogate their Accounting systems for identifying the anomalies which can be indicators of fraud by running advanced analytics\n",
      "Tools & Technologies: HTML, JavaScript, SqlServer, JQuery, CSS, Bootstrap, Node.js, D3.js, DC.js\n",
      "\n",
      "Average length in characters: 3160.364864864865\n"
     ]
    }
   ],
   "source": [
    "print(f\"sample {df_updatedResumeDataset.iloc[0]['Resume']}\\n\")\n",
    "print(f\"Average length in characters: {df_updatedResumeDataset['Resume'].str.len().mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data.csv [Job Descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_jd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mdata_jd\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_data\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_jd' is not defined"
     ]
    }
   ],
   "source": [
    "df_data = pd.read_csv(data_jd+\"data.csv\")\n",
    "print(f\"Shape: {df_data.shape}\")\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Job Description:  Location: Plano, TX or Oklahoma City, OK Duration: Internship During Summer 2017 Term Job Summary:  Visual BI Solutions Inc is seeking Graduate Interns with strong expertise/passion in BI or Big Data & Analytics Solutions (SAP BW or SAP HANA or Oracle / MS SQL EDW / PL/SQL / BODS / SAS / Big Data / Visualization Tools) to join our College Recruiting Hiring Program. In this role, you would be building best-in-class BI, Analytics & Big Data Solutions that would be consumed by leaders and executives of Fortune 500 organizations.  A strong sense of business analysis, ETL, Data Modeling, Data Warehousing, Visualization, Reporting, Advanced Analytics and data interpretation are some of the key attributes we look for. As a market leader in SAP BI & Analytics - Visual BI is very selective in student hiring and so candidates with portfolio of non-academic project work/technical blogs will be preferred over work experience or academic GPA Scores. You will be asked to hone your BI & Analytics expertise during your internship and you will be working with some of the best customers and BI talent in the world Requirements-2+ years of IT BI / EDW / ETL / Big Data development or Relevant Work BI/DataWarehousing experience is Preferred -Visual BI will consider your non-academic projects to showcase your experience in these areas -Experience with SAP HANA or SAP BW or SAP BODS or Big Data Frameworks (Hadoop/Spark, ..) a PLUS- Candidates with Reporting or Web Development Skills (CSS/JavaScript/UI5/Fiori) will also be considereBenefits Be on the forefront of learning and innovation! You'll have 24x7 access to Visual BI Labs, our learning environment that hosts all leading-edge innovations in BI with excellent training and development opportunities during Internship  10 - 12 weeks of Paid Internship  Opportunities to secure full-time roles in BI & Analytics with Visual BI  \n",
      "\n",
      "Average length in characters: 3758.1783439490446\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample Job Description: {df_data.iloc[0]['Job Description']}\\n\")\n",
    "print(f\"Average length in characters: {df_data['Job Description'].str.len().mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2664, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>link</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist / Bioinformatician, Drug Develo...</td>\n",
       "      <td>HyperMabs Inc.</td>\n",
       "      <td>Montréal, QC</td>\n",
       "      <td>https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>['· Cooperate with company leadership to devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist (Paid Internship)</td>\n",
       "      <td>FPT Software</td>\n",
       "      <td>Montréal, QC</td>\n",
       "      <td>https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>['- Senior undergraduate in Computer Science/M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Air Miles</td>\n",
       "      <td>Temporarily Remote in Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>['Demonstrate understanding of overall busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>newNLP Data Scientist (Remote)</td>\n",
       "      <td>Wisedocs AI</td>\n",
       "      <td>Remote in Toronto, ON</td>\n",
       "      <td>https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>['Experience building and deploying predictive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>ACI World</td>\n",
       "      <td>Hybrid remote in Montréal, QC</td>\n",
       "      <td>https://ca.indeed.com/pagead/clk?mo=r&amp;ad=-6NYl...</td>\n",
       "      <td>&lt;div class=\"jobsearch-jobDescriptionText\" id=\"...</td>\n",
       "      <td>['· Assist supervisor in enhancing the overall...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                               title         company  \\\n",
       "0  Data Scientist / Bioinformatician, Drug Develo...  HyperMabs Inc.   \n",
       "1                   Data Scientist (Paid Internship)    FPT Software   \n",
       "2                                     Data Scientist       Air Miles   \n",
       "3                     newNLP Data Scientist (Remote)     Wisedocs AI   \n",
       "4                                     Data Scientist       ACI World   \n",
       "\n",
       "                            location  \\\n",
       "0                       Montréal, QC   \n",
       "1                       Montréal, QC   \n",
       "2  Temporarily Remote in Toronto, ON   \n",
       "3              Remote in Toronto, ON   \n",
       "4      Hybrid remote in Montréal, QC   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "1  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "2  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "3  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "4  https://ca.indeed.com/pagead/clk?mo=r&ad=-6NYl...   \n",
       "\n",
       "                                         description  \\\n",
       "0  <div class=\"jobsearch-jobDescriptionText\" id=\"...   \n",
       "1  <div class=\"jobsearch-jobDescriptionText\" id=\"...   \n",
       "2  <div class=\"jobsearch-jobDescriptionText\" id=\"...   \n",
       "3  <div class=\"jobsearch-jobDescriptionText\" id=\"...   \n",
       "4  <div class=\"jobsearch-jobDescriptionText\" id=\"...   \n",
       "\n",
       "                                              skills  \n",
       "0  ['· Cooperate with company leadership to devel...  \n",
       "1  ['- Senior undergraduate in Computer Science/M...  \n",
       "2  ['Demonstrate understanding of overall busines...  \n",
       "3  ['Experience building and deploying predictive...  \n",
       "4  ['· Assist supervisor in enhancing the overall...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scientist = pd.read_csv(os.path.join(data_jd, \"DataScientist.csv\"))\n",
    "print(f\"Shape: {df_data_scientist.shape}\")\n",
    "df_data_scientist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5305.515015015015"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scientist[\"description\"].apply(len).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<div class=\"jobsearch-jobDescriptionText\" id=\"jobDescriptionText\">\\n<p>HyperMabs Inc. is a fast growing, values driven biotechnology company based in Montreal, Canada, and we are currently looking for a highly motivated and talented <b>Data Scientist </b>who will join our growing team in our mission to develop medicines that radically transform patients’ lives.</p>\\n<p>In close collaboration with our research teams, you will be in charge of developing a state-of-the-art data analysis pipeline which integrates our research results as well as publicly available data sets. The information you deliver will drive key research and development decisions and directly generate value for our researchers and patients.</p>\\n<p>This is an opportunity to help shape the data strategy of a highly entrepreneurial biotechnology venture and grow by working closely with an experienced team of drug development experts with a successful industry track record. The position would be an excellent fit for early career professionals looking to gain and / or expand their knowledge of data science applications within the field of pharmaceutical biotechnology.</p>\\n<p><b>You will love this job if: </b></p>\\n<p>· You have a passion for science and medicine</p>\\n<p>· You thrive in a fast-paced environment and are curious to learn</p>\\n<p>· You enjoy working as a team player and value good communication</p>\\n<p><b>Key Responsibilities: </b></p>\\n<p>· In collaboration with our scientists and other stakeholders, identify R&amp;D data to capture in our database and perform investigative data analysis, data wrangling, statistical analysis, data visualization and reporting</p>\\n<p>· Curate publicly available and internal data sets, optimizing for ease of access and traceability</p>\\n<p>· Present and share insights based on your developed analysis</p>\\n<p>· Provide expertise company-wide ranging from data science &amp; analytics to more traditional statistical and computer science analysis to improve our research and workflows</p>\\n<p>· Cooperate with company leadership to develop the company’s data science strategy</p>\\n<p><b>You should bring at a minimum the following qualifications: </b></p>\\n<p>· Bachelor of Science (or equivalent) in a relevant discipline such as computer science, mathematics, bioinformatics, molecular biology, or biochemistry</p>\\n<p>· One (1) year of professional experience in an academic, data- or life-sciences setting</p>\\n<p>· Python, R or similar skills in data analysis and statistics</p>\\n<p>· Strong organizational and time management skills</p>\\n<p>· Ability to work independently, as well as collaboratively across several teams</p>\\n<p>· Excellent oral and written communication skills in English</p>\\n<p><b>Any of these qualifications in addition would be a huge plus: </b></p>\\n<p>· Graduate degree</p>\\n<p>· Biotech or other start-up experience</p>\\n<p>· Knowledge of computational image analysis</p>\\n<p>· Experience with working with genetic and proteomic data</p>\\n<p>· Knowledge of molecular modeling</p>\\n<p>· Experience with analysing clinical and epidemiological data sets</p>\\n<p>· Proven experience working on a significant project independently</p>\\n<p>· Experience in generating compelling data visualizations</p>\\n<p>Job Type: Full-time</p>\\n<p>Benefits:</p>\\n<ul>\\n<li>Commuter benefits</li>\\n<li>Company events</li>\\n<li>Dental care</li>\\n<li>Disability insurance</li>\\n<li>Employee assistance program</li>\\n<li>Extended health care</li>\\n<li>Flexible schedule</li>\\n<li>Life insurance</li>\\n<li>Paid time off</li>\\n<li>Vision care</li>\\n<li>Wellness program</li>\\n</ul>\\n<p>Schedule:</p>\\n<ul>\\n<li>Monday to Friday</li>\\n</ul>\\n<p>Experience:</p>\\n<ul>\\n<li>using Python, R in data analysis: 1 year (preferred)</li>\\n<li>working in academic, data- or life-sciences setting: 1 year (preferred)</li>\\n</ul>\\n</div>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scientist[\"description\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean html text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def get_text_from_html(text):\n",
    "    # Find all the text within the HTML content and join it into a single string\n",
    "    text = ''.join(BeautifulSoup(text, 'html.parser').stripped_strings)\n",
    "\n",
    "    # Print the extracted text without HTML tags\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove HTML tags\n",
    "        text = re.sub(r'<[^>]*>', ' ', text)\n",
    "        # Remove special characters\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        # Remove extra whitespaces\n",
    "        text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "print(len(get_text_from_html(df_data_scientist[\"description\"][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HyperMabs Inc is a fast growing values driven ...</td>\n",
       "      <td>Cooperate with company leadership to develop t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Location Montreal QuebecDuration 3 months from...</td>\n",
       "      <td>Senior undergraduate in Computer Science Mathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It s fun to work in a company where people tru...</td>\n",
       "      <td>Demonstrate understanding of overall business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>About usWe re on a mission to make it easy and...</td>\n",
       "      <td>Experience building and deploying predictive m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Position title Data ScientistReports to Senior...</td>\n",
       "      <td>Assist supervisor in enhancing the overall dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>Position Description What you can expect from ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2660</th>\n",
       "      <td>Company DescriptionShopify is now permanently ...</td>\n",
       "      <td>Strong sense of ownership and growth mindset s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>OverviewICON plc is a world leading healthcare...</td>\n",
       "      <td>Actively seeks new business opportunities with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>Introduction Our goal at Pivotree is to help a...</td>\n",
       "      <td>Experience with Agile development practices Ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>NeurosciencePsychology GeneralManagement Syste...</td>\n",
       "      <td>Effective interpersonal skills Organized Excel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2664 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            description  \\\n",
       "0     HyperMabs Inc is a fast growing values driven ...   \n",
       "1     Location Montreal QuebecDuration 3 months from...   \n",
       "2     It s fun to work in a company where people tru...   \n",
       "3     About usWe re on a mission to make it easy and...   \n",
       "4     Position title Data ScientistReports to Senior...   \n",
       "...                                                 ...   \n",
       "2659  Position Description What you can expect from ...   \n",
       "2660  Company DescriptionShopify is now permanently ...   \n",
       "2661  OverviewICON plc is a world leading healthcare...   \n",
       "2662  Introduction Our goal at Pivotree is to help a...   \n",
       "2663  NeurosciencePsychology GeneralManagement Syste...   \n",
       "\n",
       "                                                 skills  \n",
       "0     Cooperate with company leadership to develop t...  \n",
       "1     Senior undergraduate in Computer Science Mathe...  \n",
       "2     Demonstrate understanding of overall business ...  \n",
       "3     Experience building and deploying predictive m...  \n",
       "4     Assist supervisor in enhancing the overall dat...  \n",
       "...                                                 ...  \n",
       "2659                                                     \n",
       "2660  Strong sense of ownership and growth mindset s...  \n",
       "2661  Actively seeks new business opportunities with...  \n",
       "2662  Experience with Agile development practices Ex...  \n",
       "2663  Effective interpersonal skills Organized Excel...  \n",
       "\n",
       "[2664 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_scientist['description'] = df_data_scientist['description'].apply(get_text_from_html)\n",
    "df_data_scientist['description'] = df_data_scientist['description'].apply(clean_text)\n",
    "df_data_scientist['skills'] = df_data_scientist['skills'].apply(clean_text)\n",
    "\n",
    "df_data_scientist = df_data_scientist[[\"description\", \"skills\"]]\n",
    "df_data_scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average description length is: 4056 characters\n",
      "Average skills length is: 1562 characters\n"
     ]
    }
   ],
   "source": [
    "average_description_length = df_data_scientist[\"description\"].str.len().mean()\n",
    "average_skills_length = df_data_scientist[\"skills\"].str.len().mean()\n",
    "print(f\"Average description length is: {average_description_length:.0f} characters\")\n",
    "print(f\"Average skills length is: {average_skills_length:.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_scientist.to_pickle('df_data_scientist_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3220"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_data_scientist[\"description\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            combined_description_skills\n",
      "0     HyperMabs Inc is a fast growing values driven ...\n",
      "1     Location Montreal QuebecDuration 3 months from...\n",
      "2     It s fun to work in a company where people tru...\n",
      "3     About usWe re on a mission to make it easy and...\n",
      "4     Position title Data ScientistReports to Senior...\n",
      "...                                                 ...\n",
      "2659  Position Description What you can expect from ...\n",
      "2660  Company DescriptionShopify is now permanently ...\n",
      "2661  OverviewICON plc is a world leading healthcare...\n",
      "2662  Introduction Our goal at Pivotree is to help a...\n",
      "2663  NeurosciencePsychology GeneralManagement Syste...\n",
      "\n",
      "[2664 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame by concatenating \"description\" and \"skills\"\n",
    "combined_df = pd.DataFrame({\n",
    "    \"combined_description_skills\": df_data_scientist[\"description\"] + \" \" + df_data_scientist[\"skills\"]\n",
    "})\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files have been saved.\n"
     ]
    }
   ],
   "source": [
    "# now save each row in a new txt file\n",
    "# Define a directory to save the text files\n",
    "output_directory = \"/Users/andreasloutzidis/Downloads/jobLLMatch/Datasets/job_descriptions/data_scientist_txt\"\n",
    "\n",
    "# Iterate through the rows and save each row in a separate text file\n",
    "for index, row in combined_df.iterrows():\n",
    "    file_name = f\"data_scientist_jd_row_{index}.txt\"\n",
    "    with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        file.write(row[\"combined_description_skills\"])\n",
    "print(\"Text files have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
